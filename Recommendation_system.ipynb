{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13461969,"sourceType":"datasetVersion","datasetId":8545080},{"sourceId":269877391,"sourceType":"kernelVersion"}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nfrom collections import defaultdict\n\n\nimport numpy as np\nimport pandas as pd\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\nroc_auc_score,\nroc_curve,\nconfusion_matrix,\naccuracy_score,\nprecision_score,\nrecall_score,\nf1_score,\nclassification_report,\n)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import make_pipeline\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nsns.set(style=\"whitegrid\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:26:50.685518Z","iopub.execute_input":"2025-10-23T08:26:50.685807Z","iopub.status.idle":"2025-10-23T08:26:50.694173Z","shell.execute_reply.started":"2025-10-23T08:26:50.685782Z","shell.execute_reply":"2025-10-23T08:26:50.693151Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# ----------------------\n# Configuration\n# ----------------------\nMOVIES_FILE = '/kaggle/input/datatrw/data2.csv'\nRATINGS_FILE = '/kaggle/input/datatrw/data3.csv'\nUSERS_FILE = '/kaggle/input/datatrw/data4.csv'\nOUTPUT_DIR = '/kaggle/working/'\n\nRATING_THRESHOLD = 4 # rating >= 4 => liked (positive class)\nTEST_SIZE = 0.2\nRANDOM_STATE = 42\n\n\nos.makedirs(OUTPUT_DIR, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:26:50.695317Z","iopub.execute_input":"2025-10-23T08:26:50.695674Z","iopub.status.idle":"2025-10-23T08:26:50.712092Z","shell.execute_reply.started":"2025-10-23T08:26:50.695644Z","shell.execute_reply":"2025-10-23T08:26:50.710887Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# ----------------------\n# Utility functions\n# ----------------------\n\ndef load_movies(path):\n    \"\"\"Load movies file; expects MovieID::Title::Genres\"\"\"\n    df = pd.read_csv(path, sep=\"::\", engine=\"python\", header=None, names=[\"movieId\", \"title\", \"genres\"])\n    # extract year from title if available\n    def extract_year(t):\n        m = re.search(r\"\\((\\d{4})\\)\", str(t))\n        return int(m.group(1)) if m else np.nan\n\n    df[\"year\"] = df[\"title\"].apply(extract_year)\n    return df\n\n\ndef load_ratings(path):\n    \"\"\"Load ratings file; expects UserID::MovieID::Rating::Timestamp\"\"\"\n    df = pd.read_csv(path, sep=\"::\", engine=\"python\", header=None, names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])\n    return df\n\n\ndef load_users(path):\n    \"\"\"Load users file; expects UserID::Gender::Age::Occupation::Zip-code\"\"\"\n    df = pd.read_csv(path, sep=\"::\", engine=\"python\", header=None, names=[\"userId\", \"gender\", \"age\", \"occupation\", \"zip\"])\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:26:50.712955Z","iopub.execute_input":"2025-10-23T08:26:50.713194Z","iopub.status.idle":"2025-10-23T08:26:50.726132Z","shell.execute_reply.started":"2025-10-23T08:26:50.713177Z","shell.execute_reply":"2025-10-23T08:26:50.725218Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# ----------------------\n# Load data\n# ----------------------\nprint(\"Loading data...\")\nmovies = load_movies(MOVIES_FILE)\nratings = load_ratings(RATINGS_FILE)\nusers = load_users(USERS_FILE)\n\nprint(f\"movies: {movies.shape}, ratings: {ratings.shape}, users: {users.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:26:50.728219Z","iopub.execute_input":"2025-10-23T08:26:50.728452Z","iopub.status.idle":"2025-10-23T08:26:56.310814Z","shell.execute_reply.started":"2025-10-23T08:26:50.728435Z","shell.execute_reply":"2025-10-23T08:26:56.310014Z"}},"outputs":[{"name":"stdout","text":"Loading data...\nmovies: (3883, 4), ratings: (1000209, 4), users: (6040, 5)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"#import pandas as pd\n#import matplotlib.pyplot as plt\n#import os \n\n# ---------- Basic EDA & Preprocessing ----------\ndef basic_eda(movies_path, ratings_path, OUTPUT_DIR):\n    # Load datasets correctly (double-colon separated)\n    movies = pd.read_csv(\n        movies_path,\n        sep=\"::\",\n        names=[\"movieId\", \"title\", \"genres\"],\n        engine=\"python\"\n    )\n    ratings = pd.read_csv(\n        ratings_path,\n        sep=\"::\",\n        names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"],\n        engine=\"python\"\n    )\n\n    # Ensure movieId types match for merging\n    movies[\"movieId\"] = movies[\"movieId\"].astype(int)\n    ratings[\"movieId\"] = ratings[\"movieId\"].astype(int)\n\n    # Create output directory if not exists\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n\n    # --------- Basic statistics ----------\n    stats = {\n        \"num_movies\": movies[\"movieId\"].nunique(),\n        \"num_users\": ratings[\"userId\"].nunique(),\n        \"num_ratings\": len(ratings),\n        \"rating_min\": ratings[\"rating\"].min(),\n        \"rating_max\": ratings[\"rating\"].max(),\n        \"rating_mean\": ratings[\"rating\"].mean(),\n        \"rating_median\": ratings[\"rating\"].median()\n    }\n\n    pd.Series(stats).to_frame(\"value\").to_csv(\n        os.path.join(OUTPUT_DIR, \"basic_stats.csv\")\n    )\n\n    # --------- Rating distribution ----------\n    plt.figure(figsize=(6, 4))\n    ratings[\"rating\"].value_counts().sort_index().plot(kind=\"bar\", color=\"skyblue\")\n    plt.title(\"Rating Distribution\")\n    plt.xlabel(\"Rating\")\n    plt.ylabel(\"Count\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(OUTPUT_DIR, \"rating_distribution.png\"))\n    plt.close()\n\n    # --------- Top movies by rating count ----------\n    top_movies_by_count = (\n        ratings.groupby(\"movieId\").size().reset_index(name=\"count\").sort_values(by=\"count\", ascending=False).head(20)\n    )\n\n    # Merge with movie names -------------------\n    \n    top_movies = movies.merge(top_movies_by_count, on=\"movieId\", how=\"inner\")\n    top_movies.to_csv(os.path.join(OUTPUT_DIR, \"top_movies_by_count.csv\"), index=False)\n\n    # Plot-------------------------------------\n    \n    plt.figure(figsize=(10, 5))\n    plt.barh(top_movies[\"title\"], top_movies[\"count\"], color=\"lightcoral\")\n    plt.title(\"Top 20 Movies by Rating Count\")\n    plt.xlabel(\"Number of Ratings\")\n    plt.ylabel(\"Movie Title\")\n    plt.gca().invert_yaxis()\n    plt.tight_layout()\n    plt.savefig(os.path.join(OUTPUT_DIR, \"top_movies_by_count.png\"))\n    plt.close()\n\n    # --------- Ratings per user ----------\n    user_rating_count = (\n        ratings.groupby(\"userId\").size().reset_index(name=\"count\")\n    )\n    plt.figure(figsize=(6, 4))\n    plt.hist(user_rating_count[\"count\"], bins=50, color=\"lightgreen\")\n    plt.title(\"Ratings per User Distribution\")\n    plt.xlabel(\"Number of Ratings\")\n    plt.ylabel(\"Users Count\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(OUTPUT_DIR, \"ratings_per_user.png\"))\n    plt.close()\n\n    print(f\"âœ… EDA output saved to '{OUTPUT_DIR}' successfully!\")\n\n\n# ---------- Example usage ----------\n# basic_eda(\"path_to/movies.dat\", \"path_to/ratings.dat\", \"OUTPUT\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:08:34.748042Z","iopub.execute_input":"2025-10-23T09:08:34.748474Z","iopub.status.idle":"2025-10-23T09:08:34.764225Z","shell.execute_reply.started":"2025-10-23T09:08:34.748454Z","shell.execute_reply":"2025-10-23T09:08:34.763281Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# ---------- Merge and Feature Engineering (Clean + Optimized) ----------\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\nprint(\"ðŸ”§ Cleaning, merging, and engineering features...\")\n\n# --- Clean unwanted quotes or spaces in all object columns ---\nfor df_ in [users, movies, ratings]:\n    for col in df_.select_dtypes(include=\"object\").columns:\n        df_[col] = df_[col].astype(str).str.strip().str.replace('\"', '', regex=False)\n\n# --- Ensure consistent numeric column types before merging ---\nratings[\"movieId\"] = ratings[\"movieId\"].astype(int)\nmovies[\"movieId\"] = movies[\"movieId\"].astype(int)\nratings[\"userId\"] = ratings[\"userId\"].astype(int)\nusers[\"userId\"] = users[\"userId\"].astype(int)\nif \"age\" in users.columns:\n    users[\"age\"] = users[\"age\"].fillna(0).astype(int)\n\n# --- Handle missing genres and create one-hot encoded genre features ---\nmovies[\"genres\"] = movies[\"genres\"].fillna(\"\")\ngenre_dummies = movies[\"genres\"].str.get_dummies(sep=\"|\").add_prefix(\"genre_\")\nmovies = pd.concat([movies, genre_dummies], axis=1)\n\n# --- Merge ratings + movies + users ---\ndf = (\n    ratings\n    .merge(movies, on=\"movieId\", how=\"left\")\n    .merge(users, on=\"userId\", how=\"left\")\n)\n\n# --- Create binary target label (liked = 1 if rating >= threshold) ---\nRATING_THRESHOLD = 3.5\ndf[\"liked\"] = (df[\"rating\"] >= RATING_THRESHOLD).astype(int)\n\n# --- Encode gender ---\ndf[\"gender\"] = df[\"gender\"].fillna(\"M\")\nle_gender = LabelEncoder()\ndf[\"gender_enc\"] = le_gender.fit_transform(df[\"gender\"])\n\n# --- Encode occupation (if categorical) ---\nif df[\"occupation\"].dtype == \"object\":\n    df[\"occupation\"] = df[\"occupation\"].fillna(\"Unknown\")\n    le_occ = LabelEncoder()\n    df[\"occupation_enc\"] = le_occ.fit_transform(df[\"occupation\"])\n    occ_col = \"occupation_enc\"\nelse:\n    df[\"occupation\"] = df[\"occupation\"].fillna(0).astype(int)\n    occ_col = \"occupation\"\n\n# --- Compute movie and user rating counts ---\nmovie_rating_count = df.groupby(\"movieId\")[\"rating\"].count().reset_index(name=\"movie_rating_count\")\nuser_rating_count = df.groupby(\"userId\")[\"rating\"].count().reset_index(name=\"user_rating_count\")\n\ndf = (\n    df.merge(movie_rating_count, on=\"movieId\", how=\"left\")\n      .merge(user_rating_count, on=\"userId\", how=\"left\")\n)\n\n# --- Define feature columns ---\ngenre_cols = [c for c in df.columns if c.startswith(\"genre_\")]\nfeature_cols = [\"gender_enc\", \"age\", occ_col, \"movie_rating_count\", \"user_rating_count\"] + genre_cols\n\n# --- Fill missing numeric values and scale features ---\nfor col in feature_cols:\n    if df[col].dtype == \"object\":\n        df[col] = df[col].fillna(\"Unknown\")\n    else:\n        df[col] = df[col].fillna(0)\n\nscaler = StandardScaler()\ndf[[\"movie_rating_count\", \"user_rating_count\", \"age\"]] = scaler.fit_transform(\n    df[[\"movie_rating_count\", \"user_rating_count\", \"age\"]]\n)\n\n# --- Prepare final X and y ---\nX = df[feature_cols]\ny = df[\"liked\"]\n\nprint(\"âœ… Feature engineering completed successfully!\")\nprint(f\"Final dataset shape: {df.shape}\")\nprint(f\"Feature columns ({len(feature_cols)}): {feature_cols[:10]} ...\")\nprint(f\"Target distribution:\\n{df['liked'].value_counts(normalize=True)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:30:06.717520Z","iopub.execute_input":"2025-10-23T08:30:06.717846Z","iopub.status.idle":"2025-10-23T08:30:16.973097Z","shell.execute_reply.started":"2025-10-23T08:30:06.717823Z","shell.execute_reply":"2025-10-23T08:30:16.972251Z"}},"outputs":[{"name":"stdout","text":"ðŸ”§ Cleaning, merging, and engineering features...\nâœ… Feature engineering completed successfully!\nFinal dataset shape: (1000209, 189)\nFeature columns (179): ['gender_enc', 'age', 'occupation', 'movie_rating_count', 'user_rating_count', 'genre_Action', 'genre_Action,,,,,,', 'genre_Action,,,,,,,', 'genre_Action,,,,,,,,', 'genre_Action,,,,,,,,,'] ...\nTarget distribution:\nliked\n1    0.575161\n0    0.424839\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# ----------------------\n# Train/test split\n# ----------------------\nprint(\"Splitting into train/test...\")\ntrain_df, test_df = train_test_split(df, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=df[\"liked\"])\n\nprint(\"Train:\", train_df.shape, \"Test:\", test_df.shape)\n\n# ----------------------\n# Baseline: Popularity predictor\n# ----------------------\nprint(\"Training popularity baseline...\")\nmost_common_label = train_df[\"liked\"].mode()[0]\n\ndef predict_popularity(df_):\n    return np.full(len(df_), most_common_label)\n\n# evaluate function\n\ndef evaluate_binary(y_true, y_pred, y_score=None, model_name=\"model\"):\n    acc = accuracy_score(y_true, y_pred)\n    prec = precision_score(y_true, y_pred, zero_division=0)\n    rec = recall_score(y_true, y_pred, zero_division=0)\n    f1 = f1_score(y_true, y_pred, zero_division=0)\n    auc = roc_auc_score(y_true, y_score) if y_score is not None else None\n    cm = confusion_matrix(y_true, y_pred)\n    return {\"model\": model_name, \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"auc\": auc, \"confusion_matrix\": cm}\n\nresults = []\n\npop_pred = predict_popularity(test_df)\n# for popularity we don't have a score; we'll use proportion of positives in train as score\npop_score = np.full(len(test_df), train_df[\"liked\"].mean())\nres_pop = evaluate_binary(test_df[\"liked\"], pop_pred, y_score=pop_score, model_name=\"popularity\")\nresults.append(res_pop)\n\n# save confusion matrix image\ncm = res_pop[\"confusion_matrix\"]\nplt.figure()\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\nplt.title(\"Popularity baseline Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.savefig(os.path.join(OUTPUT_DIR, \"cm_popularity.png\"))\nplt.close()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:30:47.419335Z","iopub.execute_input":"2025-10-23T08:30:47.420774Z","iopub.status.idle":"2025-10-23T08:30:52.854797Z","shell.execute_reply.started":"2025-10-23T08:30:47.420746Z","shell.execute_reply":"2025-10-23T08:30:52.853851Z"}},"outputs":[{"name":"stdout","text":"Splitting into train/test...\nTrain: (800167, 189) Test: (200042, 189)\nTraining popularity baseline...\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"#import numpy as np\n#import pandas as pd\n#from sklearn.neighbors import NearestNeighbors\n\n# --------------------------------------------------------------------------\n                        #collaborative filtering\n# --------------------------------------------------------------------------\n\nprint(\"Building user-item matrix for CF...\")\nuser_item = train_df.pivot_table(index=\"userId\", columns=\"movieId\", values=\"rating\")\nuser_item_filled = user_item.fillna(0)\n\nprint(\"Training user-based kNN model (cosine similarity)...\")\nuser_nn = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\", n_neighbors=30, n_jobs=-1)\nuser_nn.fit(user_item_filled.values)\n\n# Precompute neighbors for all users\nprint(\"Precomputing neighbors...\")\ndistances, neighbor_indices = user_nn.kneighbors(user_item_filled.values, n_neighbors=30)\n\n# Map userId to row index\nuser_index_map = {uid: idx for idx, uid in enumerate(user_item_filled.index)}\n\n# Precompute movie average ratings for fallback\nmovie_stats = train_df.groupby('movieId')['rating'].agg(movie_avg_rating='mean').reset_index()\nmovie_avg_map = movie_stats.set_index('movieId')['movie_avg_rating'].to_dict()\nglobal_mean = train_df['rating'].mean()\n\nprint(\"Predicting test set with fast user-based CF...\")\n\ndef fast_predict_user_cf(test_df, k=20):\n    preds = np.zeros(len(test_df))\n    \n    for i, (uid, mid) in enumerate(zip(test_df['userId'], test_df['movieId'])):\n        if uid not in user_index_map:\n            # Cold-start user\n            preds[i] = movie_avg_map.get(mid, global_mean)\n            continue\n        \n        uidx = user_index_map[uid]\n        neighbors = neighbor_indices[uidx][:k]\n        neighbor_user_ids = user_item_filled.index[neighbors]\n\n        # Collect neighbor ratings for this movie\n        ratings = []\n        for nu in neighbor_user_ids:\n            if mid in user_item.columns and not pd.isna(user_item.loc[nu, mid]):\n                ratings.append(user_item.loc[nu, mid])\n        \n        if ratings:\n            preds[i] = np.mean(ratings)\n        else:\n            # Cold-start movie\n            preds[i] = movie_avg_map.get(mid, global_mean)\n    \n    return preds\n\n# Run fast prediction\nuser_cf_pred_ratings = fast_predict_user_cf(test_df)\nuser_cf_pred_labels = (user_cf_pred_ratings >= RATING_THRESHOLD).astype(int)\n\n# Evaluate as before\nres_user_cf = evaluate_binary(test_df['liked'], user_cf_pred_labels, \n                              y_score=user_cf_pred_ratings, model_name='user_cf')\nresults.append(res_user_cf)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:42:11.178329Z","iopub.execute_input":"2025-10-23T08:42:11.179232Z","iopub.status.idle":"2025-10-23T08:43:08.787248Z","shell.execute_reply.started":"2025-10-23T08:42:11.179207Z","shell.execute_reply":"2025-10-23T08:43:08.786479Z"}},"outputs":[{"name":"stdout","text":"Building user-item matrix for CF...\nTraining user-based kNN model (cosine similarity)...\nPrecomputing neighbors...\nPredicting test set with fast user-based CF...\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# ----------------------------\n# ROC Curve & Confusion Matrix for all models\n# ----------------------------\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_curve, auc, confusion_matrix\n\n# List of models and predictions\nmodels_info = [\n    {\n        \"name\": \"Popularity Baseline\",\n        \"y_true\": test_df['liked'],\n        \"y_pred\": np.full(len(test_df), most_common_label),\n        \"y_score\": np.full(len(test_df), train_df['liked'].mean())  # probability estimate\n    },\n    {\n        \"name\": \"User-CF\",\n        \"y_true\": test_df['liked'],\n        \"y_pred\": user_cf_pred_labels,\n        \"y_score\": user_cf_pred_ratings\n    },\n    # Add other models here if available, e.g., RandomForest, SVD\n    # Example for RandomForest:\n    # {\n    #     \"name\": \"RandomForest\",\n    #     \"y_true\": y_test,\n    #     \"y_pred\": rf_preds,\n    #     \"y_score\": rf_probs\n    # },\n]\n\nfor model in models_info:\n    name = model['name']\n    y_true = model['y_true']\n    y_pred = model['y_pred']\n    y_score = model['y_score']\n\n    # --- ROC Curve ---\n    fpr, tpr, _ = roc_curve(y_true, y_score)\n    roc_auc = auc(fpr, tpr)\n    plt.figure()\n    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n    plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'{name} ROC Curve')\n    plt.legend(loc=\"lower right\")\n    plt.savefig(os.path.join(OUTPUT_DIR, f'roc_{name.replace(\" \", \"_\").lower()}.png'))\n    plt.close()\n\n    # --- Confusion Matrix ---\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(5, 4))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title(f'{name} Confusion Matrix')\n    plt.savefig(os.path.join(OUTPUT_DIR, f'cm_{name.replace(\" \", \"_\").lower()}.png'))\n    plt.close()\n\nprint(\"âœ… ROC curves and confusion matrices saved for all models.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:59:44.672471Z","iopub.execute_input":"2025-10-23T08:59:44.672902Z","iopub.status.idle":"2025-10-23T08:59:45.271547Z","shell.execute_reply.started":"2025-10-23T08:59:44.672878Z","shell.execute_reply":"2025-10-23T08:59:45.270474Z"}},"outputs":[{"name":"stdout","text":"âœ… ROC curves and confusion matrices saved for all models.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# ----------------------\n# Comparison and summary\n# ----------------------\nprint(\"Compiling results and saving summary...\")\n\nsummary_rows = []\nfor r in results:\n    summary_rows.append({\n        'model': r['model'],\n        'accuracy': r['accuracy'],\n        'precision': r['precision'],\n        'recall': r['recall'],\n        'f1': r['f1'],\n        'auc': r['auc'] if r['auc'] is not None else np.nan,\n    })\nsummary_df = pd.DataFrame(summary_rows).sort_values(by='f1', ascending=False)\nsummary_df.to_csv(os.path.join(OUTPUT_DIR, 'model_comparison.csv'), index=False)\n\nplt.figure(figsize=(8, 4))\nsummary_df.set_index('model')[['accuracy', 'precision', 'recall', 'f1', 'auc']].plot(kind='bar')\nplt.title('Model comparison')\nplt.tight_layout()\nplt.savefig(os.path.join(OUTPUT_DIR, 'model_comparison.png'))\nplt.close()\n\nprint(\"All outputs saved to the 'outputs' folder.\")\nprint(summary_df)\n\n# End of script\nprint('Done')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:50:08.290373Z","iopub.execute_input":"2025-10-23T08:50:08.290719Z","iopub.status.idle":"2025-10-23T08:50:08.614043Z","shell.execute_reply.started":"2025-10-23T08:50:08.290697Z","shell.execute_reply":"2025-10-23T08:50:08.613155Z"}},"outputs":[{"name":"stdout","text":"Compiling results and saving summary...\nAll outputs saved to the 'outputs' folder.\n        model  accuracy  precision    recall        f1       auc\n0  popularity  0.575159   0.575159  1.000000  0.730287  0.500000\n1     user_cf  0.671964   0.698628  0.755615  0.726005  0.717798\n2     user_cf  0.671964   0.698628  0.755615  0.726005  0.717798\nDone\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x400 with 0 Axes>"},"metadata":{}}],"execution_count":30}]}